# -*- coding: utf-8 -*-
"""
speech_to_text.py
-----------------
Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï†Ï‰Î½Î·Ï„Î¹ÎºÎ®Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… â€” online (OpenAI Whisper) Î® offline (faster_whisper).
Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ ÎµÏ€Î¹Î»Î¿Î³Î® Î¼Î¹ÎºÏÎ¿Ï†ÏÎ½Î¿Ï… Î¼Î­ÏƒÏ‰ Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î®Ï‚ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚ MIC_DEVICE_INDEX.
"""

import os
import sys
import queue
import numpy as np
import sounddevice as sd
import soundfile as sf
import tempfile
import traceback
import torch

# === OpenAI API ===
try:
    import openai
    _OPENAI_OK = True
except Exception:
    _OPENAI_OK = False

# === Faster Whisper ===
try:
    from faster_whisper import WhisperModel
    _FW_OK = True
except Exception:
    _FW_OK = False

# === Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ===
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_MS = 30

# Î•Ï€Î¹Î»Î¿Î³Î® Î¼Î¹ÎºÏÎ¿Ï†ÏÎ½Î¿Ï… Î¼Î­ÏƒÏ‰ Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î®Ï‚ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚
ENV_MIC_INDEX = os.environ.get("MIC_DEVICE_INDEX")
if ENV_MIC_INDEX and ENV_MIC_INDEX.isdigit():
    device_index = int(ENV_MIC_INDEX)
    print(f"ğŸ§ [Audio] MIC_DEVICE_INDEX Î±Ï€ÏŒ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½: {device_index}")
else:
    # Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Ï€ÏÏÏ„Î¿ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Î¼Î¹ÎºÏÏŒÏ†Ï‰Î½Î¿
    device_index = 0
    print(f"ğŸšï¸ [Audio] Î ÏÏÏ„Î¿ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ input -> #{device_index} (default)")

USE_OPENAI = True if _OPENAI_OK else False
USE_FASTER_WHISPER = True if _FW_OK else False

LANGUAGE = "el"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘ ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥ ===
if USE_FASTER_WHISPER:
    try:
        whisper_model = WhisperModel("small", device=DEVICE)
        print(f"ğŸ§  [FasterWhisper] Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ ({DEVICE})")
    except Exception as e:
        print(f"âš ï¸ [FasterWhisper] Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚: {e}")
        whisper_model = None
        USE_FASTER_WHISPER = False
else:
    whisper_model = None

# === Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î— Î•Î“Î“Î¡Î‘Î¦Î—Î£ ===
def _record_once(duration=5):
    """ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® Ï†Ï‰Î½Î®Ï‚ Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î±."""
    try:
        audio = sd.rec(
            int(duration * SAMPLE_RATE),
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype="float32",
            device=device_index
        )
        sd.wait()
        return np.squeeze(audio)
    except Exception as e:
        print(f"âš ï¸ [Audio Record] Î£Ï†Î¬Î»Î¼Î±: {e}")
        return None

# === ÎšÎ¥Î¡Î™Î‘ ÎšÎ›Î‘Î£Î— ===
class SpeechToText:
    def __init__(self):
        self.online = USE_OPENAI
        self.offline = USE_FASTER_WHISPER
        self.client = openai if _OPENAI_OK else None

        if self.online:
            print("ğŸŒ [STT Online] OpenAI Whisper Î­Ï„Î¿Î¹Î¼Î¿.")
        elif self.offline:
            print("ğŸ§  [STT Offline] Faster Whisper Î­Ï„Î¿Î¹Î¼Î¿.")
        else:
            print("âš ï¸ [STT] Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎµÎ½ÎµÏÎ³ÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿ â€” Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ stub fallback.")

    def listen_once(self, duration=5):
        """ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® ÎºÎ±Î¹ Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï†Ï‰Î½Î®Ï‚ ÏƒÎµ ÎºÎµÎ¯Î¼ÎµÎ½Î¿."""
        audio = _record_once(duration=duration)
        if audio is None:
            print("[SpeechToText] (stub) fallback ÎµÎ½ÎµÏÎ³ÏŒ â€” ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎºÎµÎ½ÏŒ string.")
            return ""

        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï WAV
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                sf.write(f.name, audio, SAMPLE_RATE)
                wav_path = f.name
        except Exception as e:
            print(f"âš ï¸ [STT] Î£Ï†Î¬Î»Î¼Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {e}")
            return ""

        text = ""
        if self.online and self.client:
            try:
                with open(wav_path, "rb") as af:
                    resp = self.client.audio.transcriptions.create(
                        model="whisper-1",
                        file=af,
                        language=LANGUAGE
                    )
                text = resp.text.strip()
                return text
            except Exception as e:
                print(f"âš ï¸ [STT Online] Î£Ï†Î¬Î»Î¼Î±: {e}")

        if self.offline and whisper_model:
            try:
                segments, _ = whisper_model.transcribe(wav_path, language=LANGUAGE)
                text = " ".join([seg.text for seg in segments]).strip()
                return text
            except Exception as e:
                print(f"âš ï¸ [STT Offline] Î£Ï†Î¬Î»Î¼Î±: {e}")

        print("[SpeechToText] (stub) fallback ÎµÎ½ÎµÏÎ³ÏŒ â€” ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎºÎµÎ½ÏŒ string.")
        return ""

